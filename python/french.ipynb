{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENLEXICON\n",
    "\n",
    "* For french language\n",
    "* tools for NLP\n",
    "* https://github.com/chrplr/openlexicon/tree/master/scripts\n",
    "* download \n",
    "* http://www.lexique.org/\n",
    "* http://www.lexique.org/databases/Lexique382/Lexique382.tsv\n",
    "\n",
    "* http://www.lexique.org/databases/Lexique383/Lexique383.zip\n",
    "* all databases\n",
    "* http://www.lexique.org/databases/\n",
    "\n",
    "## WORDLEX\n",
    "\n",
    "* http://www.lexique.org/?page_id=250\n",
    "* in 66 languages\n",
    "\n",
    "### english\n",
    "\n",
    "* http://www.lexique.org/databases/WorldLex/Eng_US.Freq.2.txt.gz\n",
    "* http://www.lexique.org/databases/WorldLex/Eng_US.Freq.3.Hun.txt.gz\n",
    "* http://worldlex.lexique.org/files/Eng_US.Freq.3.rar\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save file \n",
    "# http://www.lexique.org/databases/Lexique383/Lexique383.zip\n",
    "!curl -O http://www.lexique.org/databases/Lexique383/Lexique383.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save file \n",
    "# http://worldlex.lexique.org/files/Eng_US.Freq.3.rar\n",
    "!curl -O http://worldlex.lexique.org/files/Eng_US.Freq.3.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save file \n",
    "# http://worldlex.lexique.org/files/Eng_US.Freq.3.rar\n",
    "!curl -O http://worldlex.lexique.org/files/Eng_US.Freq.3.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python package rarfile\n",
    "!pip install rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract files from archive \n",
    "# lexique/Eng_US.Freq.2.rar\n",
    "import rarfile\n",
    "rar = rarfile.RarFile('lexique/Eng_US.Freq.2.rar')\n",
    "rar.extractall('lexique')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download http://www.lexique.org/databases/Lexique382/Lexique382.tsv\n",
    "# and save in my-data lexique382.tsv\n",
    "\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import os\n",
    "\n",
    "# check if the file exists\n",
    "file_tsv = \"my-data/lexique382.tsv\"\n",
    "\n",
    "if os.path.isfile(file_tsv):\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    print(\"File does not exist\")\n",
    "    print(\"Downloading file...\")\n",
    "    # download the file\n",
    "    url = \"http://www.lexique.org/databases/Lexique382/Lexique382.tsv\"\n",
    "    r = rq.get(url)\n",
    "    # save it\n",
    "    with open(file_tsv, \"wb\") as f:\n",
    "        f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Exemple de sélection d'items dans la base Lexique382 \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "lex = pd.read_csv(\"my-data/lexique382.tsv\", sep='\\t')\n",
    "\n",
    "lex.head()\n",
    "\n",
    "# restreint la recherche à des mots de longueur comprises entre 5 et 8 lettres\n",
    "subset = lex.loc[(lex.nblettres >= 5) & (lex.nblettres <=8)]\n",
    "\n",
    "# separe les noms et les verbes dans deux dataframes:\n",
    "noms = subset.loc[subset.cgram == 'NOM']\n",
    "verbs = subset.loc[subset.cgram == 'VER']\n",
    "\n",
    "# sectionne sur la bases de la fréquence lexicale\n",
    "noms_hi = noms.loc[noms.freqlivres > 50.0]\n",
    "noms_low = noms.loc[(noms.freqlivres < 10.0) & (noms.freqlivres > 1.0)]\n",
    "\n",
    "verbs_hi = verbs.loc[verbs.freqlivres > 50.0]\n",
    "verbs_low = verbs.loc[(verbs.freqlivres < 10.0) & (verbs.freqlivres > 1.0)]\n",
    "\n",
    "# choisi des items tirés au hasard dans chacun des 4 sous-ensembles:\n",
    "N = 20\n",
    "noms_hi.sample(N).ortho.to_csv('my-data/nomhi.txt', index=False)\n",
    "noms_low.sample(N).ortho.to_csv('my-data/nomlo.txt', index=False)\n",
    "verbs_hi.sample(N).ortho.to_csv('my-data/verhi.txt', index=False)\n",
    "verbs_hi.sample(N).ortho.to_csv('my-data/verlo.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lhtr my-data/lexique382.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load database in a dataframe\n",
    "# from file lexique/lexique382.tsv\n",
    "import pandas as pd\n",
    "lex = pd.read_csv(\"my-data/lexique382.tsv\", sep='\\t')\n",
    "\n",
    "# select words with 5 to 8 letters\n",
    "subset = lex.loc[(lex.nblettres >= 5) & (lex.nblettres <=8)]\n",
    "\n",
    "# separate nouns and verbs in two dataframes:\n",
    "noms = subset.loc[subset.cgram == 'NOM']\n",
    "verbs = subset.loc[subset.cgram == 'VER']\n",
    "\n",
    "# show the number of words in each category\n",
    "print(\"noms: \", len(noms))\n",
    "print(\"verbs: \", len(verbs))\n",
    "\n",
    "# select on the basis of lexical frequency\n",
    "noms_hi = noms.loc[noms.freqlivres > 50.0]\n",
    "noms_low = noms.loc[(noms.freqlivres < 10.0) & (noms.freqlivres > 1.0)]\n",
    "\n",
    "verbs_hi = verbs.loc[verbs.freqlivres > 50.0]\n",
    "verbs_low = verbs.loc[(verbs.freqlivres < 10.0) & (verbs.freqlivres > 1.0)]\n",
    "\n",
    "# show the number of words in each category\n",
    "print(\"noms_hi: \", len(noms_hi))\n",
    "\n",
    "# show in a dataframe\n",
    "# noms_hi.head(100)\n",
    "# show all rows and columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "noms_hi\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load database\n",
    "# from file lexique/lexique382.tsv\n",
    "# and export as sqlite database\n",
    "import pandas as pd\n",
    "\n",
    "# load database in a dataframe\n",
    "lex = pd.read_csv(\"lexique/lexique383.tsv\", sep='\\t')\n",
    "\n",
    "# create a sqlite database\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('lexique/lexique383.sqlite')\n",
    "\n",
    "# export the dataframe to the database\n",
    "lex.to_sql('lexique383', conn, if_exists='replace', index=False)\n",
    "\n",
    "# close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index on the database lexique/lexique382.sqlite\n",
    "# on the column ortho\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('lexique/lexique383.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute(\"CREATE INDEX ortho_index ON lexique383 (ortho);\")\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLITE\n",
    "\n",
    "* size in tsv: 25M\n",
    "* size in sqlite without index: 28M\n",
    "* size in sqlite with index: 30M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load database in a dataframe\n",
    "# from sqlite file lexique/lexique382.sqlite\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('lexique/lexique382.sqlite')\n",
    "lex = pd.read_sql_query(\"SELECT * FROM lexique382\", conn)\n",
    "conn.close()\n",
    "\n",
    "# select words with 5 to 8 letters\n",
    "\n",
    "subset = lex.loc[(lex.nblettres >= 5) & (lex.nblettres <=8)]\n",
    "\n",
    "# separate nouns and verbs in two dataframes:\n",
    "noms = subset.loc[subset.cgram == 'NOM']\n",
    "verbes = subset.loc[subset.cgram == 'VER']\n",
    "\n",
    "# show the number of words in each category\n",
    "print(\"noms: \", len(noms))\n",
    "print(\"verbes: \", len(verbes))\n",
    "\n",
    "# show the first 10 rows\n",
    "dn = noms.head(10)\n",
    "\n",
    "# show the first 10 rows\n",
    "dv = verbes.head(10)\n",
    "\n",
    "display(dn)\n",
    "display(dv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
