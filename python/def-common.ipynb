{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of functions to be used in ipynb notebooks\n",
    "\n",
    "async def handle_request(route, request):\n",
    "    # print(request.url)\n",
    "    # if request is js, abort it\n",
    "    if request.resource_type == \"script\":\n",
    "        # print(\"Aborting request: \" + request.url)\n",
    "        await route.abort()\n",
    "    else:\n",
    "        await route.continue_()\n",
    "\n",
    "async def read_webpage (url, tag, selector=\"h3\"):\n",
    "    from playwright.async_api import async_playwright\n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch()\n",
    "    page = await browser.new_page()\n",
    "\n",
    "    # create folder my-data if not exists\n",
    "    # !mkdir -p my-data\n",
    "\n",
    "    # block js requests\n",
    "    await page.route(\"**/*\", handle_request)\n",
    "\n",
    "    # set timeout to 5s\n",
    "    await page.goto(url, timeout=5000)\n",
    "    \n",
    "    # save screenshot in file with timestamp ymd-his\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    snow = now.strftime('%Y%m%d-%H%M%S')\n",
    "    filename = f\"my-data/shot-{tag}-{snow}.png\"\n",
    "    await page.screenshot(path=filename, full_page=True)\n",
    "\n",
    "\n",
    "    # get all titles h3\n",
    "    my_titles = []\n",
    "    titles = await page.query_selector_all(selector)\n",
    "    for title in titles:\n",
    "        # add title to list\n",
    "        tt = await title.inner_text()\n",
    "        my_titles.append(tt)\n",
    "        # print(await title.inner_text())\n",
    "\n",
    "    # concatenate all titles in one string with separator newline\n",
    "    txt_titles = \"\"\n",
    "\n",
    "    for title in my_titles:\n",
    "        txt_titles += title + \"\\n\"\n",
    "\n",
    "    # print(txt_titles)\n",
    "    # build html page with titles\n",
    "    html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    <title>News {tag}</title>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>News {tag}</h1>\n",
    "    <pre>{txt_titles}</pre>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    # show html page in a ipynb widget\n",
    "    from IPython.display import HTML\n",
    "    wid_html = HTML(html)\n",
    "    display(wid_html)\n",
    "    \n",
    "    # save my_titles in plain file with one title per line\n",
    "    with open(f\"my-data/titles-{tag}-{snow}.txt\", 'w') as f:\n",
    "            f.write(str(txt_titles))\n",
    "\n",
    "    # save my_titles in json file\n",
    "    import json\n",
    "    with open(f\"my-data/titles-{tag}-{snow}.json\", 'w') as f:\n",
    "        json.dump(my_titles, f)\n",
    "\n",
    "\n",
    "    await browser.close()\n",
    "    await playwright.stop()\n",
    "\n",
    "# show screenshot\n",
    "#from IPython.display import Image\n",
    "#Image(filename=filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of functions to be used in ipynb notebooks\n",
    "\n",
    "async def handle_request_db(route, request):\n",
    "    # print(request.url)\n",
    "    # if request is js, abort it\n",
    "    if request.resource_type == \"script\":\n",
    "        # print(\"Aborting request: \" + request.url)\n",
    "        await route.abort()\n",
    "    else:\n",
    "        await route.continue_()\n",
    "\n",
    "def insert_news_db (titles, tag, url, sdatetime):\n",
    "    # write to db\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('my-data/news.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS news (id INTEGER PRIMARY KEY, md5 TEXT, tag TEXT, title TEXT, url TEXT, date TEXT)')\n",
    "    # add unique index on md5 is not exists\n",
    "    c.execute('CREATE UNIQUE INDEX IF NOT EXISTS idx_md5 ON news (md5)')\n",
    "\n",
    "    # count duplicates\n",
    "    ndup = 0\n",
    "    for tt in titles:\n",
    "        # trim title\n",
    "        tt = tt.strip()\n",
    "        # if title is empty, skip it\n",
    "        if not tt:\n",
    "            continue\n",
    "\n",
    "        # md5 hash of title\n",
    "        import hashlib\n",
    "        mhash = hashlib.md5()\n",
    "        mhash.update(tt.encode('utf-8'))\n",
    "        mhash = mhash.hexdigest()\n",
    "        # try to insert title in db with md5 hash\n",
    "        # catch error if title already exists\n",
    "        try:\n",
    "            c.execute('INSERT INTO news (md5, tag, title, url, date) VALUES (?, ?, ?, ?, ?)', (mhash, tag, tt, url, sdatetime))\n",
    "        except sqlite3.IntegrityError:\n",
    "            ndup += 1\n",
    "            # print(\"Title already exists: \" + tt)\n",
    "\n",
    "    # print number of duplicates\n",
    "    print(\"Number of duplicates: \" + str(ndup))\n",
    "    # get the number of rows in the table\n",
    "    c.execute('SELECT COUNT(*) FROM news')\n",
    "    print(\"Number of rows in table news: \" + str(c.fetchone()[0]))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "async def read_webpage_db (url, tag, selector=\"h3\"):\n",
    "    from playwright.async_api import async_playwright\n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch()\n",
    "    page = await browser.new_page()\n",
    "\n",
    "    # create folder my-data if not exists\n",
    "    # !mkdir -p my-data\n",
    "\n",
    "    # block js requests\n",
    "    await page.route(\"**/*\", handle_request_db)\n",
    "\n",
    "    # set timeout to 5s\n",
    "    await page.goto(url, timeout=10000)\n",
    "        \n",
    "    # save screenshot in file with timestamp ymd-his\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    snow = now.strftime('%Y%m%d-%H%M%S')\n",
    "    sdatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    filename = f\"my-data/shot-{tag}-{snow}.png\"\n",
    "    await page.screenshot(path=filename, full_page=True)\n",
    "\n",
    "\n",
    "    # get all titles h3\n",
    "    my_titles = []\n",
    "    titles = await page.query_selector_all(selector)\n",
    "\n",
    "    for title in titles:\n",
    "        # add title to list\n",
    "        tt = await title.inner_text()\n",
    "        # trim title\n",
    "        tt = tt.strip()\n",
    "        # if title is empty, skip it\n",
    "        if not tt:\n",
    "            continue\n",
    "        my_titles.append(tt)\n",
    "        # print(await title.inner_text())\n",
    "\n",
    "    # insert titles in db\n",
    "    insert_news_db(my_titles, tag, url, sdatetime)\n",
    "\n",
    "    # concatenate all titles in one string with separator newline\n",
    "    txt_titles = \"\"\n",
    "\n",
    "    for title in my_titles:\n",
    "        txt_titles += f\"<li>{title}</li>\\n\"\n",
    "\n",
    "    # print(txt_titles)\n",
    "    # build html page with titles\n",
    "    html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    <title>News {tag}</title>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>News {tag}</h1>\n",
    "    <ol>\n",
    "    {txt_titles}\n",
    "    </ol>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    # show html page in a ipynb widget\n",
    "    from IPython.display import HTML\n",
    "    wid_html = HTML(html)\n",
    "    display(wid_html)\n",
    "    \n",
    "    # save my_titles in plain file with one title per line\n",
    "    # with open(f\"my-data/titles-{tag}-{snow}.txt\", 'w') as f:\n",
    "    #        f.write(str(txt_titles))\n",
    "\n",
    "    # save my_titles in json file\n",
    "    # import json\n",
    "    # with open(f\"my-data/titles-{tag}-{snow}.json\", 'w') as f:\n",
    "    #    json.dump(my_titles, f)\n",
    "\n",
    "\n",
    "    await browser.close()\n",
    "    await playwright.stop()\n",
    "\n",
    "# show screenshot\n",
    "#from IPython.display import Image\n",
    "#Image(filename=filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read titles from db\n",
    "def read_titles_db (tag=\"\"):\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('my-data/news.db')\n",
    "    c = conn.cursor()\n",
    "    if tag == \"\":\n",
    "        c.execute('SELECT title FROM news')\n",
    "    else:\n",
    "        c.execute('SELECT title FROM news WHERE tag = ?', (tag,))\n",
    "    titles = c.fetchall()\n",
    "    conn.close()\n",
    "    return titles\n",
    "\n",
    "# loop in titles and split words, then add to dictionary\n",
    "def count_words_db (tag=\"\"):\n",
    "    # read titles from db\n",
    "    titles = read_titles_db(tag)\n",
    "    # loop in titles and split words, then add to dictionary\n",
    "    words = {}\n",
    "    # articles = [\"a\", \"an\", \"the\"]\n",
    "    articles = [ \n",
    "        \"a\", \"e\", \"u\", \"es\", \"de\", \"la\", \"le\", \"des\", \"les\", \"La\", \"-\",\n",
    "        \"va\", \"nos\",\n",
    "        \"en\", \"du\", \"Ã \", \"un\", \"une\", \"et\", \"aux\", \"se\", \"si\",\n",
    "        \"ou\", \"mais\", \"ni\", \"car\", \"or\", \"donc\", \"or\", \n",
    "        \"pour\", \"sur\", \"Le\", \"au\", \"dans\", \n",
    "        \"Les\", \"plus\", \"son\", \"par\", \"est\", \n",
    "        \"avec\", \"sont\", \"qui\", \"que\", \n",
    "        \"ce\", \"ces\", \"ces\", \"ceux\", \"celui\", \"celle\", \"celles\", \n",
    "        \"leurs\", \"leur\", \"sa\", \"ses\", \"son\", \"sont\", \"soit\", \"soient\",\n",
    "        \"pas\", \"ne\", \"non\", \"ni\", \"n'\",\n",
    "        \"Au\", \"aprÃ¨s\", \"nous\", \"Ãªtre\", \"avoir\", \"avons\", \"avez\", \"ont\", \"c'est\",\n",
    "        \"Avec\", \"d'une\", \"En\", \"vous\", \"veut\", \"faire\", \"fait\", \"faites\", \"fait\",\n",
    "        \"on\", \"on\", \"elles\", \"ils\", \"il\", \"elle\", \"Il\", \"Elle\",\n",
    "        \"Ã\", \"n'est\", \"selon\", \"dâune\", \"figaro\", \"cette\", \"cet\",\n",
    "        \"notre\", \"entre\", \"oÃ¹\", \"avant\", \"quand\", \"dans\", \"dÃ¨s\", \n",
    "        \"chez\", \"sous\", \"sans\", \"contre\", \"devant\", \"derriÃ¨re\", \n",
    "        \"prÃ¨s\", \"jusqu'Ã \", \"jusquâau\", \"jusquâaux\",\n",
    "        \"faut-il\",\n",
    "    ]\n",
    "    # show number of titles\n",
    "    print(f\"Number of titles: {len(titles)}\")\n",
    "\n",
    "    for tt in titles:\n",
    "        # split title in words\n",
    "        for ww in tt[0].split():\n",
    "            # if word is not in dictionary, add it\n",
    "            # lowercase word\n",
    "            ww = ww.lower()\n",
    "            # trim punctuation\n",
    "            ww = ww.strip(\",.;:!?()[]{}'\\\"Â«Â»\")\n",
    "            # FIXME: left trim l'\n",
    "            # ww = ww.lstrip(\"l'\")\n",
    "            # FIXME: left trim d'\n",
    "            # ww = ww.lstrip(\"d'\")\n",
    "\n",
    "            # if word is empty, skip it\n",
    "            if not ww:\n",
    "                continue\n",
    "            if ww not in words:\n",
    "                words[ww] = 1\n",
    "            else:\n",
    "                # if word is punctation, decrease counter\n",
    "                if ww in [\",\", \".\", \":\", \";\", \"!\", \"?\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"'\", '\"', 'Â«', 'Â»']:\n",
    "                    words[ww] -= 1\n",
    "                # if word is article, decrease counter\n",
    "                elif ww in articles:\n",
    "                    words[ww] -= 1\n",
    "                else:\n",
    "                    # if word is in dictionary, increase counter\n",
    "                    words[ww] += 1\n",
    "    return words\n",
    "\n",
    "# show words in a bar chart\n",
    "def show_words_db (max=50, tag=\"\"):\n",
    "    \n",
    "    # count words\n",
    "    words = count_words_db(tag)\n",
    "    # sort words by descending order\n",
    "    words = dict(sorted(words.items(), key=lambda item: item[1], reverse=True))\n",
    "    # show only max words\n",
    "    words = dict(list(words.items())[0:max])\n",
    "\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/barh.html\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # show words in a bar chart with keys in vertical axis and horizontal bars\n",
    "    plt.barh(range(len(words)), list(words.values()), align='center')\n",
    "    # show label for each bar\n",
    "    for i, v in enumerate(words.values()):\n",
    "        plt.text(v, i, str(v))\n",
    "    # show keys in vertical axis\n",
    "    plt.yticks(range(len(words)), list(words.keys()))\n",
    "    \n",
    "    # invert vertical axis\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # show grid\n",
    "    plt.grid(axis='x')\n",
    "\n",
    "    # resize plt\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,max*0.25)\n",
    "\n",
    "    # show chart\n",
    "    plt.show()\n",
    "\n",
    "    # plt.bar(words.keys(), words.values())\n",
    "    # plt.show()\n",
    "\n",
    "    # print words\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curl_upload (name, file, url):\n",
    "    # send file with curl\n",
    "    cmd = f\"curl -F \\\"{name}=@{file}\\\" {url}\"\n",
    "    print(cmd)\n",
    "    !{cmd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_request_nojs(route, request):\n",
    "    # print(request.url)\n",
    "    # if request is js, abort it\n",
    "    if request.resource_type == \"script\":\n",
    "        # print(\"Aborting request: \" + request.url)\n",
    "        await route.abort()\n",
    "    else:\n",
    "        await route.continue_()\n",
    "\n",
    "async def parse_google_search (page, parse_params=None):\n",
    "    # find all titles a h3\n",
    "    titles = await page.query_selector_all('a h3')\n",
    "    index = 0\n",
    "\n",
    "    out = \"\"\n",
    "    for title in titles:\n",
    "        index += 1\n",
    "        print(f\"\\n{index}\")\n",
    "        print(await title.inner_text())\n",
    "        # https://playwright.dev/docs/other-locators\n",
    "        # get parent a href\n",
    "        link = await title.query_selector('xpath=..')\n",
    "        link = await link.get_attribute('href')\n",
    "        print(link)\n",
    "        out += f\"{index}\\n{await title.inner_text()}\\n{link}\\n\\n\"\n",
    "\n",
    "    # save titles in a file if param save is not null\n",
    "    param_save = parse_params.get(\"save\") or None\n",
    "    if param_save:\n",
    "        param_search = parse_params.get(\"search\") or None\n",
    "        with open(param_save, \"w\") as f:\n",
    "            f.write(f\"{param_search}\\n{out}\")\n",
    "\n",
    "# call function parse_page provided as function parameter\n",
    "async def playwright_page (url, target, show=True, nojs=True, parse=None, parse_params=None):\n",
    "    print(\"url:\", url)\n",
    "\n",
    "    # take a screenshot of page url\n",
    "    from playwright.async_api import async_playwright\n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch()\n",
    "    page = await browser.new_page()\n",
    "\n",
    "    # if nojs, block js\n",
    "    if nojs:\n",
    "        await page.route(\"**/*\", handle_request_nojs)\n",
    "\n",
    "    await page.goto(url)\n",
    "\n",
    "    # if parse is not null, call it\n",
    "    # https://stackoverflow.com/questions/64344862/how-to-pass-a-function-as-a-parameter-in-python\n",
    "    if parse:\n",
    "        await parse(page, parse_params)\n",
    "\n",
    "    # take a screenshot\n",
    "    target = f\"my-data/{target}.png\"\n",
    "    print(\"screenshot:\", target)\n",
    "    await page.screenshot(path=target)\n",
    "\n",
    "    await browser.close()\n",
    "    await playwright.stop()\n",
    "\n",
    "    if (show):\n",
    "        # display the image target\n",
    "        from IPython.display import Image\n",
    "        img = Image(target)\n",
    "        display(img)\n",
    "\n",
    "    return target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def google_random_search ():\n",
    "    # from sqlite file lexique/lexique383.sqlite\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('lexique/lexique383.sqlite')\n",
    "\n",
    "    # lex = pd.read_sql_query(\"SELECT * FROM lexique383\", conn)\n",
    "    \n",
    "    # get a random line with column cgram='VER'\n",
    "    line_verb = pd.read_sql_query(\"SELECT * FROM lexique383 WHERE cgram='VER' ORDER BY RANDOM() LIMIT 1\", conn)\n",
    "    # get 2 random lines with column cgram='NOM'\n",
    "    line_noun = pd.read_sql_query(\"SELECT * FROM lexique383 WHERE cgram='NOM' ORDER BY RANDOM() LIMIT 2\", conn)\n",
    "    # get a random line with column cgram='ADJ'\n",
    "    line_adj = pd.read_sql_query(\"SELECT * FROM lexique383 WHERE cgram='ADJ' ORDER BY RANDOM() LIMIT 1\", conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "    # show the word\n",
    "    sn = line_noun.ortho.values[0]\n",
    "    scomp = line_noun.ortho.values[1]\n",
    "\n",
    "    sv = line_verb.ortho.values[0]\n",
    "    sc = line_adj.ortho.values[0]\n",
    "    print(sn)\n",
    "    print(sv)\n",
    "    print(scomp)\n",
    "    print(sc)\n",
    "\n",
    "    # searchs = [sn, sv, sc, f\"{sn} {sv} {sc}\"]\n",
    "    searchs = [ f\"{sn} {sv} {scomp} {sc}\" ]\n",
    "\n",
    "    for search in searchs:\n",
    "        # url query sanitize\n",
    "        search = search.replace(' ', '+')\n",
    "        url = 'https://www.google.com/search?q=' + search\n",
    "        parse_params = { 'search': search, 'n': n, 'v': v, 'c': c, 'save': 'my-data/search.txt' }\n",
    "        await playwright_page(url, 'search', parse=parse_google_search, parse_params=parse_params)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
